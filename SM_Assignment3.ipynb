{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to drive, load data and requirements"
      ],
      "metadata": {
        "id": "SN8gYtG0g44v"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_6b0qGSm5lG"
      },
      "source": [
        "Install requirements (restart your runtime after installation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPdrkq34m0No"
      },
      "outputs": [],
      "source": [
        " !pip install simpletransformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXErwWOYm4AD"
      },
      "source": [
        "Mount google drive with data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibIjoxhrpjm1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9M3FjSfpXNX"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/SM_Assignment3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ga3cD8HppfJ"
      },
      "source": [
        "Load requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkSCfsTDpgFC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from simpletransformers.classification import ClassificationModel\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import torch\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAX84MAjq6AB"
      },
      "source": [
        "Load OLID data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRVpvgN5qpF-"
      },
      "outputs": [],
      "source": [
        "data_dir = 'data/'\n",
        "olid_train = pd.read_csv(data_dir + 'olid-train-small.csv', sep=',')\n",
        "olid_test = pd.read_csv(data_dir + 'olid-test.csv', sep=',')\n",
        "olid_train.head(5)\n",
        "olid_test.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBx7zbqW-p0B"
      },
      "source": [
        "Load Hasoc data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhJEG_ZPwEEd"
      },
      "outputs": [],
      "source": [
        "hasoc_train = pd.read_csv(data_dir + 'hasoc-train.csv', sep=',')\n",
        "hasoc_train.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# create and train models\n"
      ],
      "metadata": {
        "id": "k1Wdtytzgnf9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqQB_HqaqrdS"
      },
      "source": [
        "Load pre-trained models\n",
        "List of models [here](https://huggingface.co/models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJHqBGsAuiso"
      },
      "outputs": [],
      "source": [
        "# make models\n",
        "model_args = {}\n",
        "model_args[\"save_steps\"] = -1\n",
        "model_args[\"save_model_every_epoch\"] = False\n",
        "# pre-trained on english\n",
        "model_BERT = ClassificationModel('bert', 'bert-base-cased', args = model_args)\n",
        "# pre-trained on hate \n",
        "model_hateBERT = ClassificationModel('bert', 'GroNLP/hateBERT', args = model_args)\n",
        "model_fBERT = ClassificationModel('bert', 'diptanu/fBERT', args = model_args)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and caving in and cross models"
      ],
      "metadata": {
        "id": "rfnAK5z4gWAK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## in domain"
      ],
      "metadata": {
        "id": "j14sXfJcgZh8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdxcC0Z-Ktm6"
      },
      "outputs": [],
      "source": [
        "# train models for in-domain\n",
        "train_args = {'output_dir' : 'outputs_in/', 'overwrite_output_dir' : True}\n",
        "model_BERT.train_model(olid_train, args = train_args )\n",
        "model_fBERT.train_model(olid_train, args = train_args )\n",
        "model_hateBERT.train_model(olid_train, args =  train_args )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#saves models so training dus not have to be run again\n",
        "torch.save(model_BERT, \"outputs_in/model_BERT\")\n",
        "torch.save(model_fBERT, \"outputs_in/model_fBERT\")\n",
        "torch.save(model_hateBERT, \"outputs_in/model_hateBERT\")"
      ],
      "metadata": {
        "id": "Di94trvjcdgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## cross-domain"
      ],
      "metadata": {
        "id": "1tv3AJUOgcIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make models\n",
        "model_args = {}\n",
        "model_args[\"save_steps\"] = -1\n",
        "model_args[\"save_model_every_epoch\"] = False\n",
        "# pre-trained on english\n",
        "model_BERT_cross = ClassificationModel('bert', 'bert-base-cased', args = model_args)\n",
        "# pre-trained on hate \n",
        "model_hateBERT_cross = ClassificationModel('bert', 'GroNLP/hateBERT', args = model_args)\n",
        "model_fBERT_cross = ClassificationModel('bert', 'diptanu/fBERT', args = model_args)\n"
      ],
      "metadata": {
        "id": "tK5kdCsLkcsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAUmubqWLcYx"
      },
      "outputs": [],
      "source": [
        "# train cross models\n",
        "train_args_cross = {'output_dir' : 'outputs_cross/', 'overwrite_output_dir' : True}\n",
        "model_BERT_cross.train_model(hasoc_train, args = train_args_cross )\n",
        "model_fBERT_cross.train_model(hasoc_train, args = train_args_cross)\n",
        "model_hateBERT_cross.train_model(hasoc_train, args = train_args_cross)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save models so they do not have to be trained again\n",
        "torch.save(model_BERT_cross, \"outputs_cross/model_BERT_cross\")\n",
        "torch.save(model_fBERT_cross, \"outputs_cross/model_fBERT_cross\")\n",
        "torch.save(model_hateBERT_cross, \"outputs_in/model_hateBERT_cross\")"
      ],
      "metadata": {
        "id": "3_bpWpY4f-XW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation of models"
      ],
      "metadata": {
        "id": "07nBgxLOgiw1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## In - domain"
      ],
      "metadata": {
        "id": "ySdGRIkTgsBi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load models"
      ],
      "metadata": {
        "id": "scC5mazti-mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load models from file\n",
        "model_BERT = torch.load(\"outputs_in/model_BERT\")\n",
        "model_fBERT = torch.load(\"outputs_in/model_fBERT\")\n",
        "model_hateBERT = torch.load(\"outputs_in/model_hateBERT\")\n"
      ],
      "metadata": {
        "id": "0Ses2-a3i9Ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "Ad5QchQYjAHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# method for visualing and saving confusion matetrix\n",
        "def makeConfusionMatrix(name, cm):\n",
        "  ax = sns.heatmap(cm, annot=True, cmap='Blues', cbar = False, fmt='g' , annot_kws={\"fontsize\":16})\n",
        "  \n",
        "\n",
        "  ax.set_title(f'Confusion Matrix of {name}\\n\\n');\n",
        "  ax.set_xlabel('\\nPredicted Values')\n",
        "  ax.set_ylabel('Actual Values ');\n",
        "  \n",
        "  ## Ticket labels - List must be in alphabetical order\n",
        "  ax.xaxis.set_ticklabels(['0','1'])\n",
        "  ax.yaxis.set_ticklabels(['0','1'])\n",
        "  plt.savefig(f\"ConfusionMatrix{name}.png\", bbox_inches = 'tight') \n",
        "\n",
        "  ## Display the visualization of the Confusion Matrix.\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "O7bDMvYcr_Ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions and pring classification report and confusion matrices for in-domain\n",
        "predictions_BERT, raw_outputs_BERT = model_BERT.predict(olid_test['text'].tolist())\n",
        "predictions_fBERT, raw_outputs_fBERT = model_fBERT.predict(olid_test['text'].tolist())\n",
        "predictions_hateBERT, raw_outputs_hateBERT = model_hateBERT.predict(olid_test['text'].tolist())\n",
        "\n",
        "cm_BERT = confusion_matrix(olid_test['labels'], predictions_BERT)\n",
        "cm_fBERT = confusion_matrix (olid_test['labels'], predictions_fBERT)\n",
        "cm_hateBERT = confusion_matrix( olid_test['labels'], predictions_hateBERT)\n",
        "\n",
        "\n",
        "\n",
        "print(\"BERT\\n\")\n",
        "print(cm_BERT)\n",
        "makeConfusionMatrix(\"BERT In-domain\", cm_BERT)\n",
        "print(\"\\n\")\n",
        "print(classification_report(olid_test['labels'], predictions_BERT))\n",
        "print(\"\\n\")\n",
        "print(\"fBERT\\n\")\n",
        "makeConfusionMatrix(\"fBERT In-domain\", cm_fBERT)\n",
        "print(\"\\n\")\n",
        "print(classification_report( olid_test['labels'], predictions_fBERT))\n",
        "print(\"\\n\")\n",
        "print(\"hateBERT\\n\")\n",
        "makeConfusionMatrix(\"hateBERT In-domain\", cm_hateBERT)\n",
        "print(\"\\n\")\n",
        "print(classification_report(olid_test['labels'], predictions_hateBERT))"
      ],
      "metadata": {
        "id": "ZO3oi-xMY-rW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5atTjQf_NkPE"
      },
      "source": [
        "## Cross-domain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions and pring classification report and confusion matrices for cross-domain\n",
        "\n",
        "predictions_BERT_cross, raw_outputs_BERT_cross = model_BERT_cross.predict(olid_test['text'].tolist())\n",
        "predictions_fBERT_cross, raw_outputs_fBERT_cross = model_fBERT_cross.predict(olid_test['text'].tolist())\n",
        "predictions_hateBERT_cross, raw_outputs_hateBERT_cross = model_hateBERT_cross.predict(olid_test['text'].tolist())\n",
        "\n",
        "cm_BERT_cross = confusion_matrix(olid_test['labels'], predictions_BERT_cross)\n",
        "cm_fBERT_cross = confusion_matrix (olid_test['labels'], predictions_fBERT_cross)\n",
        "cm_hateBERT_cross = confusion_matrix( olid_test['labels'], predictions_hateBERT_cross)\n",
        "\n",
        "\n",
        "\n",
        "print(\"BERT\\n\")\n",
        "print(cm_BERT_cross)\n",
        "makeConfusionMatrix(\"BERT Cross-domain\", cm_BERT_cross)\n",
        "print(\"\\n\")\n",
        "print(classification_report(olid_test['labels'], predictions_BERT_cross))\n",
        "print(\"\\n\")\n",
        "print(\"fBERT\\n\")\n",
        "makeConfusionMatrix(\"fBERT Cross-domain\", cm_fBERT_cross)\n",
        "print(\"\\n\")\n",
        "print(classification_report( olid_test['labels'], predictions_fBERT_cross))\n",
        "print(\"\\n\")\n",
        "print(\"hateBERT\\n\")\n",
        "makeConfusionMatrix(\"hateBERT Cross-domain\", cm_hateBERT_cross)\n",
        "print(\"\\n\")\n",
        "print(classification_report(olid_test['labels'], predictions_hateBERT_cross))"
      ],
      "metadata": {
        "id": "6xqzOa9hjKvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM"
      ],
      "metadata": {
        "id": "aXcYUIRHA1GU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tqdm import tqdm\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "xeJKRrDTdYnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'reshape' data\n",
        "# filtered_train = olid_train[['text','labels']].copy()\n",
        "filtered_train = hasoc_train[['text','labels']].copy()\n",
        "filtered_test = olid_test[['text','labels']].copy()\n",
        "x_train = filtered_train['text']\n",
        "y_train = filtered_train['labels']\n",
        "\n",
        "max_dimension = 200"
      ],
      "metadata": {
        "id": "_P4WIwzkdqRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make embedding vectors\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts(x_train)\n",
        "seq = token.texts_to_sequences(x_train)\n",
        "pad_seq = pad_sequences(seq,maxlen=max_dimension)\n",
        "vocab_size = len(token.word_index)+1\n",
        "embedding_vector = {}\n",
        "#twitter embeddings\n",
        "# f = open('glove_word_embeddings/glove.twitter.27B.200d.txt')\n",
        "#Wiki embeddings\n",
        "f = open('glove_word_embeddings/glove.6B.200d.txt')\n",
        "for line in tqdm(f):\n",
        "    value = line.split(' ')\n",
        "    word = value[0]\n",
        "    coef = np.array(value[1:],dtype = 'float32')\n",
        "    embedding_vector[word] = coef\n",
        "embedding_matrix = np.zeros((vocab_size,max_dimension))\n",
        "for word,i in tqdm(token.word_index.items()):\n",
        "    embedding_value = embedding_vector.get(word)\n",
        "    if embedding_value is not None:\n",
        "        embedding_matrix[i] = embedding_value"
      ],
      "metadata": {
        "id": "CDmLZ7lzmXIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model setup\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size, max_dimension, weights = [embedding_matrix],input_length=max_dimension,trainable = False))\n",
        "model.add(keras.layers.LSTM(300))\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "g-MLld1eY8Gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fit model\n",
        "history = model.fit(pad_seq,y_train,epochs = 10,batch_size=16)"
      ],
      "metadata": {
        "id": "-mTIyRhDe8Hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test model and create confusion matrix\n",
        "x_test = filtered_test['text']\n",
        "x_test = token.texts_to_sequences(x_test)\n",
        "testing_seq = pad_sequences(x_test,maxlen=max_dimension)\n",
        "predictions =  (model.predict(testing_seq) > 0.5).astype(\"int32\")\n",
        "predicted_test = filtered_test.copy()\n",
        "predicted_test['labels'] = predictions\n",
        "predicted_test.head(10)\n",
        "predictions_lstm = predicted_test['labels']\n",
        "cm_lstm = confusion_matrix(olid_test['labels'], predictions_lstm)\n",
        "print(\"LSTM\\n\")\n",
        "print(cm_lstm)\n",
        "makeConfusionMatrix(\"LSTM Cross-domain + In-domain Embeddings)\", cm_lstm)\n",
        "print(\"\\n\")\n",
        "print(classification_report(olid_test['labels'], predictions_lstm))"
      ],
      "metadata": {
        "id": "sNfGKOtMpHmU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}